<style>
details {
  background-color: #F8F9FA;
  padding: 5px;
  border: 1px solid #ddd; /* Light border */
  border-radius: 5px; /* Rounded corners */
  margin: 10px 0; /* Spacing */
}

details summary {
  cursor: pointer; /* Pointer cursor for interactivity */
}
</style>

# Descriptive Stats V

There are statistical measures that describe the shape and distribution of data beyond simple measures of central location or dispersion. They provide a view of how data is spread out, where it concentrates, and how it deviates from what might be expected. The tools shown below describe the data's shape, symmetry, and anomalies, offering a fuller understanding of the dataset's characteristics.

## Quantiles and Percentiles {#.quartiles}

A **quantile** is a location within a set of ranked numbers (or distribution), below which a certain proportion, $q$, of that set lie. If instead express quantiles in percentage they are referred to as **percentiles**.

*Ex: Imagine all your data points lined up from smallest to largest. If you say you're looking at the 25th percentile, it means you're finding the value below which 25% of your data falls. If you had 100 test scores, the 25th percentile would be the score where 25 students scored lower than that, and 75 scored higher or equal. It's a way to see where a value stands in relation to the rest of the data in terms of percentage.*

To calculate a percentile we follow the steps below:

1. Sort the data in ascending order.

2. Compute the location of the percentile desired using $L_{p}=\frac{(n+1)P}{100}$ where $L_{p}$ is the location of the $P_{th}$ percentile, and $P$ is the percentile desired.

3. The value at $L_p$, is the the $P_{th}$ percentile.

**Example:** Let's use the IQ scores for a group of students to find the 25th percentile. $IQ=\{80,100,110,75,130,90\}$.

1. We sort the data: $IQ_{sorted}=\{75,80,90,100,110,130\}$

2. Find the location of the 25th percentile: $L_{25}=7 \times 0.25=1.75$. The 25th percentile is in the position 1.75 of the sorted data.

3. Retrieve the 25th percentile: Since position 1 is 75 and position 2 is 80, the 25th percentile lies 0.75 of the way between position 1 and 2. Hence, the 25th percentile is $P_{25}=75+0.75(5)=78.75$.

## Chevyshev's Theorem

Chebyshev's Theorem is crucial as it applies to all data distributions, and ensures that a certain proportion of data must lie between a given standard deviation from the mean. This offers a baseline to understanding the range of your data, and aids in detecting outliers. Formally, **Chevyshev's Theorem** states that regardless of the shape of the distribution, at least ($1-1/z^2$)% of the data lies between $z$ standard deviations from the mean.

*Ex: For a given data set, we want to know at least how much of the data is between two standard deviations. Substituting 2 into Chevyshev's formula yields $1-1/4=0.75. Hence, 75% of the data lies between two standard deviations from the mean.*

## The Empirical Rule

Whereas Chevyshev's theorem holds for any data distribution, the empirical rule is a bit more precise when looking at "bell shaped" data. Formally, the **Empirical Rule** or ($68$,$95$,$99.7$ rule) states that $68$%, $95$%, and $99.7$% of the data lies between $1$, $2$, and $3$ standard deviations from the mean respectively. The rule depends on the data being normally distributed.

## Outliers Z-Scores
Given the boundaries set by both the empirical rule and Chevyshev's theorem, we can classify points as being common (normal) and not common (outliers). Specifically, **outliers** are extreme deviations from the mean. They are values that are not "common" or rarely occurring. Since both the empirical rule and Chevyshev's theorem state that a large proportion of the data is between three standard deviations, it would be uncommon to have a data point that is more that three standard deviations away from the mean. 

To calculate outliers we use a z-score, which is a measure of distance from the mean in units of standard deviations. It can be calculated for any data point in your variable by using the formula $z_{i}=\frac{x_i-\bar{x}}{s_x}$. By definition, $z$-scores above $3$ are suspected to be outliers.

*Ex: On Jan 22, 2006 Kobe Bryant scored 81 points against the Toronto Raptors. He had averaged 30 point per game with a standard deviation of 4 points. If we calculate the z-score we get: $z_{81}=\frac{81-30}{4}=12.5$. This mean that 81 is 12.5 standard deviations away from the mean, making this value extremely rare.*


## Skew
The skew refers to the asymmetry in the distribution of data. If most of the data leans towards one side, it's skewed. If it leans to the left, it's left-skewed or negatively skewed, meaning the tail on the left side is longer. If it leans to the right, it's right-skewed or positively skewed, with a longer tail on the right. If the data is evenly distributed, it's not skewed at all, it's symmetric. To determine if the data is skewed, calculate the **Pearson's Coefficient of Skew**. $Sk=\frac{3(\bar {x}- Median)}{s_x}$. The distribution is skewed to the left if $Sk<0$, skewed to the right is $Sk>0$, and symmetric if $Sk=0$.

The image below shows the different types of skew:
```{r echo=FALSE, out.width="100%", fig.align='center'}
knitr::include_graphics("images/Skew.png")
```

*Ex: Assume that for a variable the mean is 10, the median is 8, and the standard deviation is 3. The pearson coefficient of skew is equal to $Sk=3(10-8)/2=3$. Since the skew is positive, we expect the distribution to be right skewed.*

## Five Point Summary

A popular way to summarize data is by calculating the minimum, first quartile, median, third quartile and maximum (five point summary). This gives us a good idea of how data is distributed. We can additionally inquire how the middle 50% of the data varies. Recall, that we can use a range to assess dispersion. The interquartile range quantifies the dispersion of the middle 50% of the data. Formally, the **interquartile range** (IQR) is the difference between the third quartile and the first quartile.

**Example:** Let's use the IQ scores for a group of students once more. Recall that the data is given by $IQ=\{80,100,110,75,130,90\}$. The minimum and the maximum are easily identified as $Max=130$ and $Min=75$. The first quartile ($P_{25}$) was calculated in [1.1](#.quartiles) as 78.75. Using the same steps the third quartile ($P_75$) is 115. The median is the average between the third and fourth numbers $Median=190/2=95$. The five point summary is given in the table below:

|$Min$|$P_{25}$|$Median$|$P_75$|$Max$|
|:-:|:-:|:-:|:-:|:-:|
|75|78.75|95|115|130|

To calculate the interquartile range we find the difference between the 75th and 25th percentiles. $IQR=115-78.75=36.25$ which means that the middle 50% of the data has a range of 36.25.

## Outliers IQR

An alternate way to identify outliers is by using the interquartile range. Specifically, we first calculate $Q_1-1.5(IQR)$ and $Q_3+1.5(IQR)$, where $Q_1$ is the first quartile, $Q_3$ is the third quartile, and $IQR$ is the interquartile range. If the observation ($x_i$) is less than $Q_1-1.5(IQR)$ or greater than $Q_3+1.5(IQR)$, then it is considered an outlier.

*Ex: Consider once more the IQ data. $IQ=\{80,100,110,75,130,90\}$. The lower limit for on outlier is given by $LL=Q_1-1.5(IQR)=78.75-1.5(36.25)$ or $LL=24.375$. The upper limit is given by $UL=Q_3+1.5(IQR)=115+1.5(36.25)$ or $UL=169.375$. Any data point outside the range [24.375,169.375] is considered an outlier. In other words, 200 and 20 would be outliers, but 100 would not.*


## Quantiles and Quartiles in R

R quickly calculates quantiles for a given variable (vector) using the `quantile()` function. Below we use the IQ example once more. 

```{r}
IQ <- c(80,100,110,75,130,90)
quantile(IQ, type=6)
```
You will notice that an extra argument *type* has been been passed into the quantile function. Since, there are several ways to calculate quantiles, R allows you to identify which method you want to use. In sec [1.1](.#quartiles) we explained method 6.

## Outliers in R

To identify outliers we can us the `scale()` function. We'll consider the first five observations in the *faithful* data set.

```{r}
head(scale(faithful),5)
```
The data shown above are z-scores for the first five observations of the faithful data set. As you can see non of the observations are outliers, as they are all less that 3 standard deviations away from the mean.

If we want to filter all observations that are say 1.3 standard deviations away from the mean, we can use the following command from `tidyverse`:

```{r message=FALSE, warning=FALSE}
library(tidyverse)
faithful %>% mutate(z_eruptions=scale(eruptions)) %>%
                      filter(scale(eruptions)>1.3)
```
This confirms that there are no outliers in the eruptions variable.

## Box Plots in R
A **box plot** is a graph that shows the five point summary, outliers (if any), and the distribution of data. It can be easily constructed using `geom_boxplot()` in R. Let's use the eruptions variable once more.

```{r message=FALSE}
library(ggthemes)
faithful %>% 
  ggplot() +
  geom_boxplot(aes(y=eruptions),
               fill="lightgrey", alpha=0.5,
               col="black", width=0.3) +
  theme_clean() +
  scale_x_continuous(breaks = NULL, limits=c(-1,1))+
  ylim(limits=c(0,6))
```
The boxplot highlights the minimum just below 2, the maximum around 5, the first quartile just above 2, the median at 4, and the third quartile just above 4. Any outlier would be shown as a point beyond the whiskers of the box plot.

Here is a summary of the functions used in this section:

- The `quantile()` function returns the five point summary when no arguments are specified. For a specific quantile, specify the *probs* argument.

- The `scale()` function calculates the z-scores for a vector of values.

- The `geom_boxplot()` command returns a box plot for a vector of values.

## Exercises

The following exercises will help you practice other statistical measures. In particular, the exercises work on:

-   Constructing a five point summary and a boxplot.

-   Applying Chebyshev's Theorem.

-   Identifying skewness.

-   Identifying outliers.

Answers are provided below. Try not to peak until you have a formulated your own answer and double checked your work for any mistakes.

### Exercise 1 {.unnumbered}

For the following exercises, make your calculations by hand and verify results using R functions when possible.

1.  Use the following observations to calculate the minimum, the first, second and third quartiles, and the maximum. Are there any outliers? Find the IQR to answer the question.

    |     |     |     |     |     |     |     |
    |:---:|:---:|:---:|:---:|:---:|:---:|:---:|
    |  3  | 10  |  4  |  1  |  0  | 30  |  6  |


<details>

<summary>Answer</summary>
*The minimum is $0$, the first quartile is $2$, second quartile is $4$, third quartile is $8$, and maximum is $30$. $30$ is an outlier since it is beyond $Q_{3}+1.5 \times IQR$.*

*Quartiles are calculated using the percentile formula $(n+1)P/100$. The data set has seven numbers. The first quartile's location is $8/4=2$, the second quartile's location is $8/2=4$ and the third quartile's location is $24/4=6$. The values at these location, when data is organized in ascending order, are $1$, $4$, and $10$.*

*In R we can get the five number summary by using the `quantile()` function. Since there are various rules that can be used to calculate percentiles, we specify type $6$ to match our rules.*

```{r}
Ex1<-c(3,10,4,1,0,30,6)
quantile(Ex1,type = 6)
```

*The interquartile range is needed to determine if there are any outliers. The $IQR$ for this data set is $Q_{3}-Q_{1}=9$. This reveals that $30$ is and outlier, since $10+1.5 \times 9=23.5$. Everything beyond $23.5$ is an outlier.*

</details>

2.  Confirm your finding of an outlier by calculating the $z$-score. Is $30$ an outlier when using a $z$-Score?

<details>

<summary>Answer</summary>
*If we use the $z$-score instead we find that $30$ is not an outlier since the $z$-score is $Z_{30}=2.15$. This observation is only $2.15$ standard deviations away from the mean.*

*In R we can make a quick calculation of the $z$-Score to confirm our results. The $z$-score is given by $Z_{i}=\frac{x_{30}-\mu}{\sigma}$.*

```{r}
(Z30<-(30-mean(Ex1))/sd(Ex1))
```

</details>

3.  Use Chebyshev's theorem to determine what percent of the data falls between the $z$-score found in $2$.

<details>

<summary>Answer</summary>
*Chebyshev's theorem states that $1-\frac{1}{z_{2}}$ of the data lies between $z$ standard deviation from the mean.*

*Substituting the $z$-score found in 2. we get $78.34$% of the data lies between the standard deviation calculated. In R:*

```{r}
1-1/(Z30)^2
```

</details>

### Exercise 2 {.unnumbered}

You will need the **Stocks** data set to answer this question. You can find this data at https://jagelves.github.io/Data/Stocks.csv The data is a sample of daily stock prices for ticker symbols TSLA (Tesla), VTI (S&P 500) and GBTC (Bitcoin).

1.  Construct a boxplot for Stock A. Is the data skewed or symmetric?

<details>

<summary>Answer</summary>
*The data is skewed to the right.*

*Start by loading the data set:*

```{r}
StockPrices<-read.csv("https://jagelves.github.io/Data/Stocks.csv")
```

*To construct the boxplot in R, use the `boxplot()` command.*

```{r}
StockPrices %>% 
  ggplot() +
  geom_boxplot(aes(y=VTI),
               fill="lightgrey", alpha=0.5,
               col="black", width=0.3) +
  theme_clean() +
  scale_x_continuous(breaks = NULL, limits=c(-1,1))
```

*The boxplot shows that there are no outliers. The data also looks like it has a slight skew to the right.*

</details>

2.  Create a histogram of the data. Include a vertical line for the mean and median. Explain how the mean and median indicates a skew in the data. Calculate the skewness statistic to confirm your result.

<details>

<summary>Answer</summary>
*The mean is more sensitive to outliers than the median. Hence, when the data is skewed to the right we expect that the mean is larger than the median.*

*Let's construct a histogram in R to search for skewness.*

```{r}
StockPrices %>% ggplot() +
  geom_histogram(aes(VTI), bins = 8,
                 binwidth = 8,
                 col="black", bg="grey",
                 boundary=179) +
  theme_clean() +
  geom_vline(xintercept = mean(StockPrices$VTI), col="black")+
  geom_vline(xintercept = median(StockPrices$VTI), col="orange")
```

*The lines are close to each other but the mean is slighlty larger than the median. Let's confirm with the skewness statistic $3(mean-median)/sd$.*

```{r}
(skew<-3*(mean(StockPrices$VTI-median(StockPrices$VTI))/sd(StockPrices$VTI)))
```

*This indicates that there is a slight skew to the right of the data.*

</details>

3.  Use a line chart to plot your data. Can you explain why the data has a skew?

<details>

<summary>Answer</summary>
*The line chart indicates that the data has a downward trend in the early periods. This creates a few points that are large. In later periods the stock price stabilizes to lower levels.*

```{r}
StockPrices %>% ggplot() +
  geom_line(aes(y=VTI, x=seq(1,length(VTI)))) + theme_clean() +
  labs(x="Period")
```

</details>

### Exercise 3 {.unnumbered}

You will need the **mtcars** data set to answer this question. This data set is part of R. You don't need to download any files to access it.

1.  Construct a boxplot for the *hp* variable. Write a command in R that retrieves the outlier. Which car is the outlier?

<details>

<summary>Answer</summary>
*The outlier is the Masserati Bora. The horse power is $335$.*

*In R we can construct a boxplot with the following command:*

```{r}
mtcars %>% 
  ggplot() +
  geom_boxplot(aes(y=hp),
               fill="lightgrey", alpha=0.5,
               col="black", width=0.3,
               outlier.colour = "red") +
  theme_clean() +
  scale_x_continuous(breaks = NULL, limits=c(-1,1))
```

*From the graph it seems like the outlier is beyond a horsepower of 275. Let's write an R command to retrieve the car.*

```{r}
mtcars %>% filter(hp>300)
```

*It's the Masserati Bora!*

</details>

2.  Create a histogram of the data. Is the data skewed? Include a vertical line for the mean and median. Calculate the skewness statistic to confirm your result.

<details>

<summary>Answer</summary>
*The histogram looks skewed to the right. This is confirmed by the estimation of a Pearson coefficient fo skewness of $1.04$.*

*In R we can construct a histogram with vertical lines for the mean and median with the following code:*

```{r}
mtcars %>% ggplot() +
  geom_histogram(aes(hp), bins = 5,
                 binwidth = 60,
                 col="black", bg="grey",
                 boundary=50) +
  theme_clean() +
  geom_vline(xintercept = mean(StockPrices$VTI), col="black")+
  geom_vline(xintercept = median(StockPrices$VTI), col="orange")
```

*The histogram looks skewed to the right. Pearson's Coefficient of Skewness is:*

```{r}
(SkewHP<-3*(mean(mtcars$hp)-median(mtcars$hp))/sd(mtcars$hp))
```

</details>

3.  Transform the data by taking a natural logarithm. Specifically, create a new variable called *Loghp*. Repeat the procedure in 2. Is the skew still there?

<details>

<summary>Answer</summary>
*The skew is still there, but the distribution now look more symmetrical and the Skew coefficient has decreased to $0.44$.*

*In R we can create an new variable that captures the log transformation. The `log()` function takes the natural logarithm of a number or vector.*

```{r}
LogHP<-log(mtcars$hp)
```

*Let's use this new variable to create our histogram:*

```{r}
ggplot() +
  geom_histogram(aes(LogHP), bins = 5,
                 col="black", bg="grey") +
  theme_clean() +
  geom_vline(xintercept = mean(LogHP), col="black")+
  geom_vline(xintercept = median(LogHP), col="orange")
```

*The mean and the variance now look closer together. The tail of the distribution (skew) now also looks diminished. The Skewness coefficient has decreased significantly:*

```{r}
(SkewLogHP<-3*(mean(LogHP)-median(LogHP))/sd(LogHP))
```


</details>

